{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocket Type Classification DNN\n",
    "#### created at : 2019-05-31\n",
    "#### last modified: \n",
    "\n",
    "### Classifier Description\n",
    "Input: (1)altitude, (2) |V_drng|, (3) V_up, (4) V_total, (5) spec E\n",
    "\n",
    "ouput: class probability [1] 170mm, [2], 240mm, [3] 300mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1290, 1)\n",
      "(1290, 5)\n"
     ]
    }
   ],
   "source": [
    "#### load data from *.mat file\n",
    "\n",
    "## load mat file\n",
    "data_all = sio.loadmat('pre_processed_data_170_240_300_BAL_5000.mat')\n",
    "data_Num = 4300\n",
    "\n",
    "## normalization vector\n",
    "std = np.array([50000, 1500, 1500, 1500, 1000000])\n",
    "\n",
    "## make np.arrays from dictionary \n",
    "input_170 = data_all['input_170'] \n",
    "input_240 = data_all['input_240'] \n",
    "input_300 = data_all['input_300'] \n",
    "\n",
    "## split data into train valid and test set\n",
    "train_Num = data_Num * 0.7\n",
    "valid_Num = data_Num * 0.2\n",
    "test_Num = data_Num * 0.1\n",
    "\n",
    "train_idx = np.arange(0,train_Num).astype(int)\n",
    "valid_idx = np.arange(train_Num, train_Num+valid_Num).astype(int)\n",
    "test_idx = np.arange(train_Num+valid_Num,data_Num).astype(int) \n",
    "\n",
    "#shuffle index\n",
    "idx_170 = np.arange(len(input_170))\n",
    "idx_240 = np.arange(len(input_240))\n",
    "idx_300 = np.arange(len(input_300))\n",
    "\n",
    "np.random.shuffle(idx_170) \n",
    "np.random.shuffle(idx_240) \n",
    "np.random.shuffle(idx_300) \n",
    "\n",
    "idx_170 = idx_170[:data_Num]\n",
    "idx_240 = idx_240[:data_Num]\n",
    "idx_300 = idx_300[:data_Num]\n",
    "  \n",
    "# shuffled data    \n",
    "X_170 = input_170[idx_170,:5]\n",
    "X_240 = input_240[idx_240,:5]\n",
    "X_300 = input_300[idx_300,:5]\n",
    "\n",
    "## make class output vectors (not one hot coding)\n",
    "D_170 = np.zeros((data_Num,1))\n",
    "D_240 = np.zeros((data_Num,1))+1\n",
    "D_300 = np.zeros((data_Num,1))+2\n",
    "#D_300[:,0] = 1; \n",
    "\n",
    "## split data set  \n",
    "X_train = np.concatenate( (X_170[train_idx,:], X_240[train_idx,:], X_300[train_idx,:]))\n",
    "D_train = np.concatenate( (D_170[train_idx,:], D_240[train_idx,:], D_300[train_idx,:]))\n",
    "\n",
    "X_valid = np.concatenate( (X_170[valid_idx,:], X_240[valid_idx,:], X_300[valid_idx,:]))\n",
    "D_valid = np.concatenate( (D_170[valid_idx,:], D_240[valid_idx,:], D_300[valid_idx,:]))\n",
    "\n",
    "X_test = np.concatenate( (X_170[test_idx,:], X_240[test_idx,:], X_300[test_idx,:]))\n",
    "D_test = np.concatenate( (D_170[test_idx,:], D_240[test_idx,:], D_300[test_idx,:]))\n",
    "\n",
    "D = torch.from_numpy(D_test)\n",
    "X = torch.from_numpy(X_test)\n",
    "print(D_test.shape)\n",
    "print(X_test.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'input_170', 'input_240', 'input_300'])\n",
      "<class 'numpy.ndarray'>\n",
      "18655\n",
      "\n",
      "[ 4007  1664  6745 ... 11418  9286 17892]\n",
      "3010\n",
      "860\n",
      "430\n",
      "\n",
      "0\n",
      "3009\n",
      "3010\n",
      "3869\n",
      "3870\n",
      "4299\n"
     ]
    }
   ],
   "source": [
    "print(type(data_all))\n",
    "print(data_all.keys())\n",
    "print(type(data_all['input_170']))\n",
    "print(len(data_all['input_170']))\n",
    "print(\"\")\n",
    "print(idx_170) \n",
    "print(len(train_idx))\n",
    "print(len(valid_idx))\n",
    "print(len(test_idx))\n",
    "print(\"\")\n",
    "print(min(train_idx))\n",
    "print(max(train_idx))\n",
    "print(min(valid_idx))\n",
    "print(max(valid_idx))\n",
    "print(min(test_idx))\n",
    "print(max(test_idx))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I wish to change the structure of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTC_net(\n",
      "  (fc1): Linear(in_features=5, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define DNN network\n",
    "class RTC_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RTC_net, self).__init__()\n",
    "        hidden_1 = 256\n",
    "        hidden_2 = 128\n",
    "        hidden_3 = 64\n",
    "        \n",
    "        self.fc1 = nn.Linear(5,hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
    "        self.fc4 = nn.Linear(hidden_3, 3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self,x):\n",
    "        x = x/std\n",
    "        x = torch.from_numpy(x).float() \n",
    "        x = x.view(-1,5) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x) \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x) \n",
    "        x = self.fc4(x) \n",
    "        return x\n",
    "    \n",
    "model = RTC_net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RTC_net(\n",
       "  (fc1): Linear(in_features=5, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = (1.0/np.sqrt(n))\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.normal_(0.1, 0.05)\n",
    "        \n",
    "model.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.fc2.bias.detach());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.fc1.weight.flatten().detach());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I wish to change the batch size from 1 to N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Train Loss 0.310855\t Valid Loss 0.197020\n",
      "val loss decreased. saving model\n",
      "Epoch: 2\t Train Loss 0.297679\t Valid Loss 0.201093\n",
      "Epoch: 3\t Train Loss 0.280050\t Valid Loss 0.181658\n",
      "val loss decreased. saving model\n",
      "Epoch: 4\t Train Loss 0.271091\t Valid Loss 0.177930\n",
      "val loss decreased. saving model\n",
      "Epoch: 5\t Train Loss 0.263744\t Valid Loss 0.173654\n",
      "val loss decreased. saving model\n",
      "Epoch: 6\t Train Loss 0.253353\t Valid Loss 0.177100\n",
      "Epoch: 7\t Train Loss 0.251114\t Valid Loss 0.161351\n",
      "val loss decreased. saving model\n",
      "Epoch: 8\t Train Loss 0.241383\t Valid Loss 0.150589\n",
      "val loss decreased. saving model\n",
      "Epoch: 9\t Train Loss 0.236126\t Valid Loss 0.147743\n",
      "val loss decreased. saving model\n",
      "Epoch: 10\t Train Loss 0.228336\t Valid Loss 0.142358\n",
      "val loss decreased. saving model\n",
      "Epoch: 11\t Train Loss 0.228297\t Valid Loss 0.139789\n",
      "val loss decreased. saving model\n",
      "Epoch: 12\t Train Loss 0.219316\t Valid Loss 0.134530\n",
      "val loss decreased. saving model\n",
      "Epoch: 13\t Train Loss 0.213254\t Valid Loss 0.130901\n",
      "val loss decreased. saving model\n",
      "Epoch: 14\t Train Loss 0.208830\t Valid Loss 0.132094\n",
      "Epoch: 15\t Train Loss 0.209185\t Valid Loss 0.129568\n",
      "val loss decreased. saving model\n",
      "Epoch: 16\t Train Loss 0.195880\t Valid Loss 0.121634\n",
      "val loss decreased. saving model\n",
      "Epoch: 17\t Train Loss 0.197850\t Valid Loss 0.120929\n",
      "val loss decreased. saving model\n",
      "Epoch: 18\t Train Loss 0.189815\t Valid Loss 0.120921\n",
      "val loss decreased. saving model\n",
      "Epoch: 19\t Train Loss 0.189201\t Valid Loss 0.116195\n",
      "val loss decreased. saving model\n",
      "Epoch: 20\t Train Loss 0.188668\t Valid Loss 0.116323\n",
      "Epoch: 21\t Train Loss 0.184811\t Valid Loss 0.111318\n",
      "val loss decreased. saving model\n",
      "Epoch: 22\t Train Loss 0.180852\t Valid Loss 0.109070\n",
      "val loss decreased. saving model\n",
      "Epoch: 23\t Train Loss 0.181374\t Valid Loss 0.108963\n",
      "val loss decreased. saving model\n",
      "Epoch: 24\t Train Loss 0.174319\t Valid Loss 0.108478\n",
      "val loss decreased. saving model\n",
      "Epoch: 25\t Train Loss 0.170803\t Valid Loss 0.106497\n",
      "val loss decreased. saving model\n",
      "Epoch: 26\t Train Loss 0.174840\t Valid Loss 0.105344\n",
      "val loss decreased. saving model\n",
      "Epoch: 27\t Train Loss 0.169755\t Valid Loss 0.102959\n",
      "val loss decreased. saving model\n",
      "Epoch: 28\t Train Loss 0.169631\t Valid Loss 0.101807\n",
      "val loss decreased. saving model\n",
      "Epoch: 29\t Train Loss 0.164671\t Valid Loss 0.100115\n",
      "val loss decreased. saving model\n",
      "Epoch: 30\t Train Loss 0.164482\t Valid Loss 0.097658\n",
      "val loss decreased. saving model\n",
      "Epoch: 31\t Train Loss 0.156916\t Valid Loss 0.100242\n",
      "Epoch: 32\t Train Loss 0.162689\t Valid Loss 0.098980\n",
      "Epoch: 33\t Train Loss 0.156737\t Valid Loss 0.092573\n",
      "val loss decreased. saving model\n",
      "Epoch: 34\t Train Loss 0.159152\t Valid Loss 0.095048\n",
      "Epoch: 35\t Train Loss 0.152896\t Valid Loss 0.091855\n",
      "val loss decreased. saving model\n",
      "Epoch: 36\t Train Loss 0.148302\t Valid Loss 0.090299\n",
      "val loss decreased. saving model\n",
      "Epoch: 37\t Train Loss 0.153594\t Valid Loss 0.098125\n",
      "Epoch: 38\t Train Loss 0.149359\t Valid Loss 0.087563\n",
      "val loss decreased. saving model\n",
      "Epoch: 39\t Train Loss 0.148426\t Valid Loss 0.086112\n",
      "val loss decreased. saving model\n",
      "Epoch: 40\t Train Loss 0.147554\t Valid Loss 0.085361\n",
      "val loss decreased. saving model\n",
      "Epoch: 41\t Train Loss 0.140129\t Valid Loss 0.093808\n",
      "Epoch: 42\t Train Loss 0.141774\t Valid Loss 0.084818\n",
      "val loss decreased. saving model\n",
      "Epoch: 43\t Train Loss 0.144144\t Valid Loss 0.101461\n",
      "Epoch: 44\t Train Loss 0.143047\t Valid Loss 0.083724\n",
      "val loss decreased. saving model\n",
      "Epoch: 45\t Train Loss 0.144235\t Valid Loss 0.083767\n",
      "Epoch: 46\t Train Loss 0.144057\t Valid Loss 0.084404\n",
      "Epoch: 47\t Train Loss 0.138723\t Valid Loss 0.079729\n",
      "val loss decreased. saving model\n",
      "Epoch: 48\t Train Loss 0.134920\t Valid Loss 0.078812\n",
      "val loss decreased. saving model\n",
      "Epoch: 49\t Train Loss 0.138612\t Valid Loss 0.080956\n",
      "Epoch: 50\t Train Loss 0.138948\t Valid Loss 0.081179\n",
      "Epoch: 51\t Train Loss 0.139915\t Valid Loss 0.080573\n",
      "Epoch: 52\t Train Loss 0.132047\t Valid Loss 0.077265\n",
      "val loss decreased. saving model\n",
      "Epoch: 53\t Train Loss 0.134132\t Valid Loss 0.074408\n",
      "val loss decreased. saving model\n",
      "Epoch: 54\t Train Loss 0.133379\t Valid Loss 0.077387\n",
      "Epoch: 55\t Train Loss 0.127608\t Valid Loss 0.075164\n",
      "Epoch: 56\t Train Loss 0.123834\t Valid Loss 0.075373\n",
      "Epoch: 57\t Train Loss 0.123783\t Valid Loss 0.073638\n",
      "val loss decreased. saving model\n",
      "Epoch: 58\t Train Loss 0.127013\t Valid Loss 0.077886\n",
      "Epoch: 59\t Train Loss 0.126214\t Valid Loss 0.072185\n",
      "val loss decreased. saving model\n",
      "Epoch: 60\t Train Loss 0.124218\t Valid Loss 0.078274\n",
      "Epoch: 61\t Train Loss 0.130157\t Valid Loss 0.075152\n",
      "Epoch: 62\t Train Loss 0.128717\t Valid Loss 0.071128\n",
      "val loss decreased. saving model\n",
      "Epoch: 63\t Train Loss 0.126009\t Valid Loss 0.067773\n",
      "val loss decreased. saving model\n",
      "Epoch: 64\t Train Loss 0.121909\t Valid Loss 0.068722\n",
      "Epoch: 65\t Train Loss 0.121368\t Valid Loss 0.068597\n",
      "Epoch: 66\t Train Loss 0.125748\t Valid Loss 0.071879\n",
      "Epoch: 67\t Train Loss 0.121362\t Valid Loss 0.065614\n",
      "val loss decreased. saving model\n",
      "Epoch: 68\t Train Loss 0.121851\t Valid Loss 0.069234\n",
      "Epoch: 69\t Train Loss 0.114754\t Valid Loss 0.066562\n",
      "Epoch: 70\t Train Loss 0.122706\t Valid Loss 0.069188\n",
      "Epoch: 71\t Train Loss 0.116522\t Valid Loss 0.069847\n",
      "Epoch: 72\t Train Loss 0.120783\t Valid Loss 0.068161\n",
      "Epoch: 73\t Train Loss 0.111900\t Valid Loss 0.061998\n",
      "val loss decreased. saving model\n",
      "Epoch: 74\t Train Loss 0.113380\t Valid Loss 0.070391\n",
      "Epoch: 75\t Train Loss 0.117066\t Valid Loss 0.070002\n",
      "Epoch: 76\t Train Loss 0.120688\t Valid Loss 0.073585\n",
      "Epoch: 77\t Train Loss 0.119546\t Valid Loss 0.077141\n",
      "Epoch: 78\t Train Loss 0.111185\t Valid Loss 0.062779\n",
      "Epoch: 79\t Train Loss 0.112986\t Valid Loss 0.066786\n",
      "Epoch: 80\t Train Loss 0.114294\t Valid Loss 0.067552\n",
      "Epoch: 81\t Train Loss 0.112827\t Valid Loss 0.066502\n",
      "Epoch: 82\t Train Loss 0.111152\t Valid Loss 0.062045\n",
      "Epoch: 83\t Train Loss 0.109146\t Valid Loss 0.064353\n",
      "Epoch: 84\t Train Loss 0.109664\t Valid Loss 0.072303\n",
      "Epoch: 85\t Train Loss 0.112449\t Valid Loss 0.060988\n",
      "val loss decreased. saving model\n",
      "Epoch: 86\t Train Loss 0.111953\t Valid Loss 0.061730\n",
      "Epoch: 87\t Train Loss 0.109027\t Valid Loss 0.074590\n",
      "Epoch: 88\t Train Loss 0.108494\t Valid Loss 0.069513\n",
      "Epoch: 89\t Train Loss 0.110801\t Valid Loss 0.063465\n",
      "Epoch: 90\t Train Loss 0.108323\t Valid Loss 0.060706\n",
      "val loss decreased. saving model\n",
      "Epoch: 91\t Train Loss 0.106854\t Valid Loss 0.062404\n",
      "Epoch: 92\t Train Loss 0.107681\t Valid Loss 0.064695\n",
      "Epoch: 93\t Train Loss 0.102158\t Valid Loss 0.056494\n",
      "val loss decreased. saving model\n",
      "Epoch: 94\t Train Loss 0.102096\t Valid Loss 0.057003\n",
      "Epoch: 95\t Train Loss 0.105212\t Valid Loss 0.064802\n",
      "Epoch: 96\t Train Loss 0.102270\t Valid Loss 0.072946\n",
      "Epoch: 97\t Train Loss 0.105929\t Valid Loss 0.059822\n",
      "Epoch: 98\t Train Loss 0.106596\t Valid Loss 0.060016\n",
      "Epoch: 99\t Train Loss 0.106472\t Valid Loss 0.055528\n",
      "val loss decreased. saving model\n",
      "Epoch: 100\t Train Loss 0.098711\t Valid Loss 0.059674\n"
     ]
    }
   ],
   "source": [
    "# train network (show train and validation loss)\n",
    "# save model when validation loss decreases\n",
    "n_epochs = 100\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epochs in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    idx = np.arange(len(X_train))\n",
    "    np.random.shuffle(idx)\n",
    "    X_train = X_train[idx,:]\n",
    "    D_train = D_train[idx]\n",
    "    \n",
    "    for N in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        data = X_train[N,:] \n",
    "        target = torch.from_numpy(D_train[N,:]).long()\n",
    "        \n",
    "        \n",
    "        \n",
    "        output = model(data)  \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    for N in range(len(X_valid)):\n",
    "        data = X_valid[N,:]\n",
    "        target = torch.from_numpy(D_valid[N,:]).long()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target) \n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss/len(X_train)\n",
    "    valid_loss = valid_loss/len(X_valid)\n",
    "    \n",
    "    print('Epoch: {}\\t Train Loss {:6f}\\t Valid Loss {:6f}'.format(\n",
    "        epochs+1, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss < valid_loss_min:\n",
    "        print(\"val loss decreased. saving model\")\n",
    "        torch.save(model.state_dict(), 'RTC_model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I need to load the pt file!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## model loading\n",
    "\n",
    "#model = RTC_net()\n",
    "#model = load('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sejoon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06355349056480467\n",
      "97.36434108527132\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prob_arr = np.zeros((len(X_test),3))\n",
    "for N in range(len(X_test)):\n",
    "    \n",
    "    data = X_test[N,:]  \n",
    "    target = torch.from_numpy(D_test[N]).long()\n",
    "\n",
    "    output = model(data)  \n",
    "    prob = F.softmax(output)\n",
    "    ii = np.argmax(prob.detach().numpy(),axis=1)   \n",
    "    test_accuracy += int(D_test[N]==ii)\n",
    "    prob_arr[N,:] = prob.detach().numpy()\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    test_loss += loss.item()\n",
    "test_loss = test_loss / len(X_test)\n",
    "test_accuracy = test_accuracy / len(X_test)\n",
    "      \n",
    "print(test_loss)\n",
    "print(test_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's VISUALIZE baby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADsFJREFUeJzt3WuMnOdZxvH/1bgpghbiYieKHNNtkYsaKpFGqySoEqQK5OBKdZEalEht3ChgVJKKQ4Vk4EOqVpUiUKmIFFJcYsVB9BAOJRY1BMu0CiAcsqEhzYEoS2qSxVa8rUNAiigkvfkwr+nU2cPs7uyMx8//J41m5p5n3vd+vLNz7XuYcaoKSVJ7XjPuBiRJ42EASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhq1YdwNLGXTpk01NTU17jYkaaI8/PDD36iqzcuNO60DYGpqipmZmXG3IUkTJcm/DTLOXUCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSo0/qTwGs1tftLC9aP3PbuEXciSacftwAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSoZQMgydYkX07yZJLHk/xSV39jkoNJnu6uN3b1JLk9yWySR5Nc3Lesnd34p5PsXL9pSZKWM8gWwMvAR6rqbcBlwM1JLgR2A4eqahtwqLsPcA2wrbvsAu6EXmAAtwKXApcAt54MDUnS6C0bAFV1rKr+qbv9X8CTwBZgB7CvG7YPeG93ewdwT/UcBs5Jcj5wFXCwqk5U1QvAQeDqoc5GkjSwFR0DSDIFvAN4EDivqo5BLySAc7thW4Dn+p4219UWq0uSxmDgAEjyeuBPgV+uqv9caugCtVqifup6diWZSTIzPz8/aHuSpBUaKACSvJbem/8fVdWfdeXnu107dNfHu/ocsLXv6RcAR5eof5eq2lNV01U1vXnz5pXMRZK0AoOcBRTgLuDJqvqdvof2AyfP5NkJ3NdXv6E7G+gy4MVuF9H9wJVJNnYHf6/sapKkMdgwwJh3Ah8Avpbkka72G8BtwL1JbgKeBa7tHjsAbAdmgZeAGwGq6kSSjwMPdeM+VlUnhjILSdKKLRsAVfV3LLz/HuCKBcYXcPMiy9oL7F1Jg5Kk9eEngSWpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhq1bAAk2ZvkeJLH+mofTfLvSR7pLtv7Hvv1JLNJnkpyVV/96q42m2T38KciSVqJQbYA7gauXqD+qaq6qLscAEhyIXAd8KPdc34vyVlJzgLuAK4BLgSu78ZKksZkw3IDquqBJFMDLm8H8Pmq+hbw9SSzwCXdY7NV9QxAks93Y59YcceSpKFYyzGAW5I82u0i2tjVtgDP9Y2Z62qL1SVJY7LaALgT+GHgIuAY8MmungXG1hL1V0myK8lMkpn5+flVtidJWs6qAqCqnq+qV6rq28Bn+M5unjlga9/QC4CjS9QXWvaeqpququnNmzevpj1J0gBWFQBJzu+7+zPAyTOE9gPXJXldkjcD24B/BB4CtiV5c5Kz6R0o3r/6tiVJa7XsQeAknwMuBzYlmQNuBS5PchG93ThHgF8AqKrHk9xL7+Duy8DNVfVKt5xbgPuBs4C9VfX40GcjSRrYIGcBXb9A+a4lxn8C+MQC9QPAgRV1J0laN34SWJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNWjYAkuxNcjzJY321NyY5mOTp7npjV0+S25PMJnk0ycV9z9nZjX86yc71mY4kaVCDbAHcDVx9Sm03cKiqtgGHuvsA1wDbussu4E7oBQZwK3ApcAlw68nQkCSNx7IBUFUPACdOKe8A9nW39wHv7avfUz2HgXOSnA9cBRysqhNV9QJwkFeHiiRphFZ7DOC8qjoG0F2f29W3AM/1jZvraovVJUljMuyDwFmgVkvUX72AZFeSmSQz8/PzQ21OkvQdG1b5vOeTnF9Vx7pdPMe7+hywtW/cBcDRrn75KfWvLLTgqtoD7AGYnp5eMCQk6UwxtftLC9aP3PbudV/3arcA9gMnz+TZCdzXV7+hOxvoMuDFbhfR/cCVSTZ2B3+v7GqSpDFZdgsgyefo/fW+KckcvbN5bgPuTXIT8CxwbTf8ALAdmAVeAm4EqKoTST4OPNSN+1hVnXpgWZI0QssGQFVdv8hDVywwtoCbF1nOXmDvirqTJK0bPwksSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUqDUFQJIjSb6W5JEkM13tjUkOJnm6u97Y1ZPk9iSzSR5NcvEwJiBJWp1hbAG8q6ouqqrp7v5u4FBVbQMOdfcBrgG2dZddwJ1DWLckaZXWYxfQDmBfd3sf8N6++j3Vcxg4J8n567B+SdIA1hoABfx1koeT7Opq51XVMYDu+tyuvgV4ru+5c13tuyTZlWQmycz8/Pwa25MkLWbDGp//zqo6muRc4GCSf1libBao1asKVXuAPQDT09OvelySNBxr2gKoqqPd9XHgi8AlwPMnd+1018e74XPA1r6nXwAcXcv6JUmrt+oASPJ9Sd5w8jZwJfAYsB/Y2Q3bCdzX3d4P3NCdDXQZ8OLJXUWSpNFbyy6g84AvJjm5nM9W1V8leQi4N8lNwLPAtd34A8B2YBZ4CbhxDeuWJK3RqgOgqp4BfmyB+jeBKxaoF3DzatcnSRouPwksSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEbxt3AmWhq95cWrB+57d0j7kTSoFr8vXULQJIaNfItgCRXA78LnAX8QVXdNuoehpX0iy1H0pnjTH6/GGkAJDkLuAP4aWAOeCjJ/qp6YpR9jEuLm5jS6eR0fBMep1FvAVwCzFbVMwBJPg/sAE6LABjXG7TBIA3XON/oJylkRh0AW4Dn+u7PAZeOuIcVG9cPdBTrXSxkVrrucS1nqZAc1rqHZVz/Fqt5HZ1ur4vT0Zkwh1TV6FaWXAtcVVU/193/AHBJVX24b8wuYFd390eAp9awyk3AN9bw/EnU2pxbmy8451asZc5vqqrNyw0a9RbAHLC17/4FwNH+AVW1B9gzjJUlmamq6WEsa1K0NufW5gvOuRWjmPOoTwN9CNiW5M1JzgauA/aPuAdJEiPeAqiql5PcAtxP7zTQvVX1+Ch7kCT1jPxzAFV1ADgwotUNZVfShGltzq3NF5xzK9Z9ziM9CCxJOn34VRCS1KiJD4AkVyd5Kslskt0LPP66JF/oHn8wydTouxyuAeb8q0meSPJokkNJ3jSOPodpuTn3jXtfkkoy8WeMDDLnJD/b/awfT/LZUfc4bAO8tn8oyZeTfLV7fW8fR5/DkmRvkuNJHlvk8SS5vfv3eDTJxUNtoKom9kLvQPK/Am8Bzgb+GbjwlDG/CHy6u30d8IVx9z2COb8L+N7u9odamHM37g3AA8BhYHrcfY/g57wN+Cqwsbt/7rj7HsGc9wAf6m5fCBwZd99rnPNPABcDjy3y+HbgL4EAlwEPDnP9k74F8P9fLVFV/wOc/GqJfjuAfd3tPwGuSJIR9jhsy865qr5cVS91dw/T+7zFJBvk5wzwceC3gP8eZXPrZJA5/zxwR1W9AFBVx0fc47ANMucCvr+7/QOc8jmiSVNVDwAnlhiyA7ineg4D5yQ5f1jrn/QAWOirJbYsNqaqXgZeBH5wJN2tj0Hm3O8men9BTLJl55zkHcDWqvqLUTa2jgb5Ob8VeGuSv09yuPum3Uk2yJw/Crw/yRy9swk/zJltpb/vKzLp/yHMQn/Jn3pa0yBjJsnA80nyfmAa+Ml17Wj9LTnnJK8BPgV8cFQNjcAgP+cN9HYDXU5vK+9vk7y9qv5jnXtbL4PM+Xrg7qr6ZJIfB/6wm/O317+9sVjX969J3wJY9qsl+sck2UBvs3GpTa7T3SBzJslPAb8JvKeqvjWi3tbLcnN+A/B24CtJjtDbV7p/wg8ED/ravq+q/reqvk7ve7O2jai/9TDInG8C7gWoqn8Avofed+acqQb6fV+tSQ+AQb5aYj+ws7v9PuBvqju6MqGWnXO3O+T36b35T/p+YVhmzlX1YlVtqqqpqpqid9zjPVU1M552h2KQ1/af0zvgT5JN9HYJPTPSLodrkDk/C1wBkORt9AJgfqRdjtZ+4IbubKDLgBer6tiwFj7Ru4Bqka+WSPIxYKaq9gN30dtMnKX3l/914+t47Qac828Drwf+uDve/WxVvWdsTa/RgHM+oww45/uBK5M8AbwC/FpVfXN8Xa/NgHP+CPCZJL9Cb1fIByf5D7okn6O3C29Td1zjVuC1AFX1aXrHObYDs8BLwI1DXf8E/9tJktZg0ncBSZJWyQCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlR/wc8XPkaSotv7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "plt.hist(prob_arr.flatten(),bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a4d1be5160>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "#ax = fig.add_subplot(111,projection='3d')\n",
    "plt.scatter(prob_arr[:,0],prob_arr[:,1],prob_arr[:,2],marker='x')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.68597238e-05, 1.04652420e-01, 1.89282335e-04, ...,\n",
       "       9.99998212e-01, 1.00000000e+00, 9.98833239e-01])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_arr[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
